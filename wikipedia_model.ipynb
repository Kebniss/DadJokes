{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wikipedia_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_deeowIYlAZs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Download PyTorch\n",
        "\n",
        "PyTorch does not come with CoLab so every time we restart this notebook we have to redownload it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R8hUE8OjxQt",
        "colab_type": "code",
        "outputId": "12f9b9e1-c186-42cc-c5d5-b5f6ae60d212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.7 (default, Oct 22 2018, 11:32:17) \\n[GCC 8.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiR67OqMlHct",
        "colab_type": "code",
        "outputId": "6e97f590-230a-470a-aed8-cc3160036bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install -q torch==1.0.0 torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 591.8MB 27kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 6.5MB/s \n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RitdEn1NlJK9",
        "colab_type": "code",
        "outputId": "1bedfdf6-8d96-4a93-d3e6-1862e8938887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcoHYcJOlSbY",
        "colab_type": "code",
        "outputId": "4fabe4ce-7fc3-41f3-9a82-9a8c4b68954b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/23/8f30a4032acc239d1f4452765f80eea2c3043b9ca33deb24a79afac354c1/pytorch_nlp-0.3.7.post1-py3-none-any.whl (83kB)\n",
            "\r\u001b[K    12% |████                            | 10kB 15.9MB/s eta 0:00:01\r\u001b[K    24% |███████▉                        | 20kB 4.3MB/s eta 0:00:01\r\u001b[K    36% |███████████▊                    | 30kB 6.1MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 40kB 4.2MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▌            | 51kB 5.0MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▌        | 61kB 5.9MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▍    | 71kB 6.7MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▎| 81kB 7.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 92kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.14.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (2.18.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (0.22.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-nlp) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->pytorch-nlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->pytorch-nlp) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas->pytorch-nlp) (1.11.0)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.3.7.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFbVkQ2lMhc",
        "colab_type": "text"
      },
      "source": [
        "# Wikipedia data for LM pretraining\n",
        "\n",
        "Our dad jokes dataset does not have that many samples so its performance is not great as-is. The major problem with having so few examples is that the model needs to learn both how to make jokes and how to compose words, and this is too much to ask of a small dataset. To learn how words are made, we are downloading a corpus based on Wikipedia to pretrain our model. We are going to use the WikiText-2 corpus that Salesforce has shared (I wanted to use WikiText-103 but CoLab doesnt give enough RAM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaB9H1emlLgw",
        "colab_type": "code",
        "outputId": "85d56e65-df44-4b9b-82fb-d7c92e0c05e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-04 17:43:54--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.101.165\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.101.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4721645 (4.5M) [application/zip]\n",
            "Saving to: ‘wikitext-2-raw-v1.zip’\n",
            "\n",
            "wikitext-2-raw-v1.z 100%[===================>]   4.50M  6.87MB/s    in 0.7s    \n",
            "\n",
            "2019-03-04 17:43:55 (6.87 MB/s) - ‘wikitext-2-raw-v1.zip’ saved [4721645/4721645]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McYSAIQrp1C_",
        "colab_type": "code",
        "outputId": "502786ce-3aa7-456a-fb1e-a1b059cb1c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!unzip wikitext-2-raw-v1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  wikitext-2-raw-v1.zip\n",
            "   creating: wikitext-2-raw/\n",
            "  inflating: wikitext-2-raw/wiki.test.raw  \n",
            "  inflating: wikitext-2-raw/wiki.valid.raw  \n",
            "  inflating: wikitext-2-raw/wiki.train.raw  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0on1av4ZKBx",
        "colab_type": "code",
        "outputId": "2d8e60d6-d7fb-4849-c02f-15e31dd1a439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!ls -lh wikitext-2-raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 13M\n",
            "-rw-rw---- 1 root root 1.3M Aug 15  2016 wiki.test.raw\n",
            "-rw-rw---- 1 root root  11M Aug 15  2016 wiki.train.raw\n",
            "-rw-rw---- 1 root root 1.1M Aug 15  2016 wiki.valid.raw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCaQSw3plgOq",
        "colab_type": "text"
      },
      "source": [
        "# Define classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEW6ttqlldIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import multiprocessing as mp\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import *\n",
        "from typing import List, Tuple\n",
        "import os\n",
        "import csv\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFhkqiCnl8HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchnlp.samplers import BucketBatchSampler\n",
        "from torchnlp.datasets import snli_dataset\n",
        "from torchnlp.utils import datasets_iterator\n",
        "from torchnlp import word_to_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PG0BYP1mJQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import tqdm as tq\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "\n",
        "\n",
        "def in_ipynb():\n",
        "    try:\n",
        "        cls = get_ipython().__class__.__name__\n",
        "        return cls == 'ZMQInteractiveShell'\n",
        "    except NameError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def in_notebook():\n",
        "    try:\n",
        "        from ipykernel.kernelapp import IPKernelApp\n",
        "        return IPKernelApp.initialized()\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def clear_tqdm():\n",
        "    inst = getattr(tq.tqdm, '_instances', None)\n",
        "    if not inst: return\n",
        "    try:\n",
        "        for i in range(len(inst)): inst.pop().close()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if in_notebook():\n",
        "    def tqdm(*args, **kwargs):\n",
        "        clear_tqdm()\n",
        "        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n",
        "    def trange(*args, **kwargs):\n",
        "        clear_tqdm()\n",
        "        return tq.trange(*args, file=sys.stdout, **kwargs)\n",
        "else:\n",
        "    from tqdm import tqdm, trange\n",
        "    tnrange=trange\n",
        "    tqdm_notebook=tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR3SE8WnmMBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List, Union\n",
        "from collections import deque\n",
        "\n",
        "class CharByteEncoder():\n",
        "  def __init__(self):\n",
        "    self.start_token = '<s>'\n",
        "    self.end_token = '</s>'\n",
        "    self.pad_token = '<pad>'\n",
        "    \n",
        "    self.start_idx = 256\n",
        "    self.end_idx = 257\n",
        "    self.pad_idx = 258\n",
        "    \n",
        "  def encode(self, s: str, pad_to=0) -> torch.LongTensor:\n",
        "    encoded = s.encode()\n",
        "    n_pad = pad_to - len(encoded) if pad_to > len(encoded) else 0\n",
        "    return torch.LongTensor([self.start_idx] + \n",
        "            [c for c in encoded] + \n",
        "            [self.end_idx] + \n",
        "            [self.pad_idx for _ in range(n_pad)]\n",
        "    )\n",
        "  \n",
        "  def decode(self, char_ids_tensor: torch.LongTensor) -> str:\n",
        "    \"\"\"\n",
        "    Decodes a list of char IDs. The structure can be like this:\n",
        "    <s>[body]</s><pad>* so we check for that.\n",
        "    \"\"\"\n",
        "    char_ids = char_ids_tensor.cpu().detach().tolist()\n",
        "    \n",
        "    out = []\n",
        "    buf = []\n",
        "    for c in char_ids:\n",
        "      if c < 256:\n",
        "        buf.append(c)\n",
        "      else:\n",
        "        if buf:\n",
        "          out.append(bytes(buf).decode())\n",
        "          buf = []\n",
        "        if c == self.start_idx:\n",
        "          out.append(self.start_token)\n",
        "        elif c == self.end_idx:\n",
        "          out.append(self.end_token)\n",
        "        elif c == self.pad_idx:\n",
        "          out.append(self.pad_token)\n",
        "      \n",
        "    if buf:  # in case some are left\n",
        "      out.append(bytes(buf).decode())\n",
        "    return ''.join(out)\n",
        "\n",
        "  def __len__(self):\n",
        "    return 259 # 256 combinations in a byte, plus 3 special chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS8XphAymONS",
        "colab_type": "code",
        "outputId": "9b0f040b-f036-4811-93a6-946b012692b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6EfUGp8mb0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WIKIPEDIA_DATA_PATH = \"wikitext-2-raw/wiki.train.raw\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9Dp1czmpvq",
        "colab_type": "text"
      },
      "source": [
        "PyTorch wants us to define a Dataset class that will be used during training. We are training our language model by having multiple sequences each batch. Each sentence needs to stay together for the LSTM to learn the sequential relationship. We are therefore making each sample a sentence, with the target being the next character. So if the input is `\"<s>hello!</s>\"` then we are going to have this: `{text: '<s>hello', next: 'hello</s>'}`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH9szwQtXN6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class WikiDataset(Dataset):\n",
        "    def __init__(self, path, char_budget=70):\n",
        "        with open(path, 'r') as fin:\n",
        "          self.data = [line.strip() for line in fin.readlines()]\n",
        "        print(f\"Dataset made of {len(self.data)} rows\")\n",
        "        self.char_budget = char_budget\n",
        "        self.text_encoder = CharByteEncoder()\n",
        "        self.samples = []\n",
        "        for _i in tqdm(range(len(self.data)), total=len(self.data)):\n",
        "            sentence = self.data.pop()\n",
        "            if sentence.startswith('='):\n",
        "              del sentence\n",
        "              continue\n",
        "            encoded_samples = self.generate_language_model_samples(sentence, \n",
        "                                                                   self.char_budget)\n",
        "            self.samples.extend(\n",
        "                (e for e in encoded_samples \n",
        "                 if len(e['text']) < 4 * self.char_budget)\n",
        "            )\n",
        "            del sentence\n",
        "        del self.data\n",
        "    \n",
        "    def get_single_sample(self, s):\n",
        "        \"\"\"\n",
        "        Input: 'my funny joke'\n",
        "        Output: {\n",
        "          text: '<s>my funny joke'\n",
        "          next: 'my funny joke</s>'\n",
        "        }\n",
        "        \"\"\"\n",
        "        encoded = self.text_encoder.encode(s)\n",
        "        return {'text': encoded[:-1], 'next': encoded[1:]}\n",
        "        \n",
        "    def generate_language_model_samples(self, sentence, char_budget_per_row):\n",
        "        \"\"\"\n",
        "        Input: \"My very funny super long string, containing lots of words\"\n",
        "        Output:\n",
        "        [\n",
        "          {\n",
        "            text: '<s>My very funny super'\n",
        "            next: 'My very funny super</s>'\n",
        "          },\n",
        "          {\n",
        "            text: '<s>long string, containing'\n",
        "            next: 'long string, containing </s>'\n",
        "          },\n",
        "          {\n",
        "            text: '<s>lots of words'\n",
        "            next: 'lots of words</s>'\n",
        "          },\n",
        "        ]\n",
        "        \"\"\"\n",
        "        \n",
        "        return [\n",
        "            self.get_single_sample(s) \n",
        "            for s in self.split_long_strings(sentence.split(), char_budget_per_row)\n",
        "        ]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.samples[i]\n",
        "    \n",
        "    def getitem_readable(self, i):\n",
        "        return {'text': self.text_encoder.decode(self.samples[i]['text']),\n",
        "               'next': self.text_encoder.decode(self.samples[i]['next'])}\n",
        "      \n",
        "    def split_long_strings(self, words: List[str], char_budget:int):\n",
        "        \"\"\"\n",
        "        Given a list of words, take words until you go over your char_budget.\n",
        "        This allows us to set a max size in chars without breaking up words.\n",
        "        If your char_budget is 1000, you should expect to hover around that\n",
        "        limit: maybe some sequences will be of size 1020, others of size 1007...\n",
        "        \"\"\"\n",
        "        cur = []\n",
        "        taken = 0\n",
        "        for i, word in enumerate(words):\n",
        "            cur.append(word)\n",
        "            taken += len(word)\n",
        "            if taken > char_budget or i == len(words)-1:\n",
        "              yield \" \".join(cur)\n",
        "              cur = []\n",
        "              taken = 0\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjPllcIEaG5A",
        "colab_type": "code",
        "outputId": "80faca7e-d932-4d2a-e67d-97bd80f3f9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "wiki_dataset = WikiDataset(WIKIPEDIA_DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset made of 36718 rows\n",
            "100%|██████████| 36718/36718 [00:06<00:00, 5962.45it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZkOWzQ_meS3",
        "colab_type": "code",
        "outputId": "b90c5afd-5322-4ec0-e9a9-e091611c0ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(wiki_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQ2u9NJc2ia",
        "colab_type": "code",
        "outputId": "0a240d07-ef88-4f8b-d318-7787d8955029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(wiki_dataset.getitem_readable(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '<s>Common starlings are trapped for food in some Mediterranean countries . The meat is tough', 'next': 'Common starlings are trapped for food in some Mediterranean countries . The meat is tough</s>'}\n",
            "{'text': '<s>and of low quality , so it is casseroled or made into pâté . One recipe said it should be stewed', 'next': 'and of low quality , so it is casseroled or made into pâté . One recipe said it should be stewed</s>'}\n",
            "{'text': '<s>\" until tender , however long that may be \" . Even when correctly prepared , it may still', 'next': '\" until tender , however long that may be \" . Even when correctly prepared , it may still</s>'}\n",
            "{'text': '<s>be seen as an acquired taste .', 'next': 'be seen as an acquired taste .</s>'}\n",
            "{'text': '<s>Mozart had a pet common starling which could sing part of his Piano Concerto in G Major', 'next': 'Mozart had a pet common starling which could sing part of his Piano Concerto in G Major</s>'}\n",
            "{'text': '<s>( KV . 453 ) . He had bought it from a shop after hearing it sing a phrase from a work he wrote', 'next': '( KV . 453 ) . He had bought it from a shop after hearing it sing a phrase from a work he wrote</s>'}\n",
            "{'text': '<s>six weeks previously , which had not yet been performed in public . He became very attached', 'next': 'six weeks previously , which had not yet been performed in public . He became very attached</s>'}\n",
            "{'text': '<s>to the bird and arranged an elaborate funeral for it when it died three years later . It', 'next': 'to the bird and arranged an elaborate funeral for it when it died three years later . It</s>'}\n",
            "{'text': '<s>has been suggested that his A Musical Joke ( K. 522 ) might be written in the comical , inconsequential', 'next': 'has been suggested that his A Musical Joke ( K. 522 ) might be written in the comical , inconsequential</s>'}\n",
            "{'text': \"<s>style of a starling 's vocalisation . Other people who have owned common starlings report\", 'next': \"style of a starling 's vocalisation . Other people who have owned common starlings report</s>\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYEhCFX2Nhm",
        "colab_type": "code",
        "outputId": "4351b7bf-8eec-4858-a70b-c8139a464dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "wiki_dataset.samples[18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'next': tensor([119, 104, 111, 108, 101,  32, 115, 101, 110, 116, 101, 110,  99, 101,\n",
              "         115,  32, 105, 110,  32,  76,  97, 116, 105, 110,  32,  97, 110, 100,\n",
              "          32,  71, 114, 101, 101, 107,  32,  44,  32,  97, 110, 100,  32, 105,\n",
              "         110,  32,  72, 101, 110, 114, 121,  32,  73,  86,  32,  44,  32,  87,\n",
              "         105, 108, 108, 105,  97, 109,  32,  83, 104,  97, 107, 101, 115, 112,\n",
              "         101,  97, 114, 101,  32, 104,  97, 100,  32,  72, 111, 116, 115, 112,\n",
              "         117, 114, 257]),\n",
              " 'text': tensor([256, 119, 104, 111, 108, 101,  32, 115, 101, 110, 116, 101, 110,  99,\n",
              "         101, 115,  32, 105, 110,  32,  76,  97, 116, 105, 110,  32,  97, 110,\n",
              "         100,  32,  71, 114, 101, 101, 107,  32,  44,  32,  97, 110, 100,  32,\n",
              "         105, 110,  32,  72, 101, 110, 114, 121,  32,  73,  86,  32,  44,  32,\n",
              "          87, 105, 108, 108, 105,  97, 109,  32,  83, 104,  97, 107, 101, 115,\n",
              "         112, 101,  97, 114, 101,  32, 104,  97, 100,  32,  72, 111, 116, 115,\n",
              "         112, 117, 114])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsVMo78isDN9",
        "colab_type": "code",
        "outputId": "6477b637-f22c-469c-a424-4dfc303a72d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "wiki_dataset.getitem_readable(1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'next': '. The success of the Petits Concerts led to them becoming an annual event ( with occasional</s>',\n",
              " 'text': '<s>. The success of the Petits Concerts led to them becoming an annual event ( with occasional'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFbqH9WAqEjH",
        "colab_type": "text"
      },
      "source": [
        "Checking that the max size of a sequence is not too bad to make sure padding and memory are taken care of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unhQWiZCpYdg",
        "colab_type": "code",
        "outputId": "e07cd3a2-aedc-4af3-d5fb-dc40827e86ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lengths = [len(p['text']) for p in wiki_dataset]\n",
        "print(max(lengths))\n",
        "plt.hist(lengths, bins=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.2400e+03, 1.5300e+02, 9.8000e+01, 1.6500e+02, 1.5100e+02,\n",
              "        4.3700e+02, 2.2900e+02, 4.2100e+02, 1.7400e+02, 1.9000e+02,\n",
              "        3.8400e+02, 2.1700e+02, 4.0700e+02, 1.9800e+02, 1.7800e+02,\n",
              "        4.1800e+02, 1.9900e+02, 4.2500e+02, 2.1900e+02, 2.1900e+02,\n",
              "        3.9400e+02, 1.9700e+02, 2.1200e+02, 4.4800e+02, 2.0200e+02,\n",
              "        4.1500e+02, 2.0700e+02, 2.0700e+02, 4.2600e+02, 1.8100e+02,\n",
              "        4.1700e+02, 2.1800e+02, 2.1700e+02, 4.3100e+02, 1.9600e+02,\n",
              "        3.7200e+02, 2.0600e+02, 1.9700e+02, 3.4900e+02, 1.8800e+02,\n",
              "        2.0300e+02, 4.0200e+02, 1.8500e+02, 3.7200e+02, 2.0100e+02,\n",
              "        1.9400e+02, 3.3100e+02, 2.0000e+02, 3.6600e+02, 1.8300e+02,\n",
              "        1.8400e+02, 3.7800e+02, 1.7500e+02, 3.4000e+02, 1.7000e+02,\n",
              "        1.8300e+02, 4.2400e+02, 4.2500e+02, 3.1240e+03, 4.1750e+03,\n",
              "        6.7510e+03, 2.0823e+04, 1.2293e+04, 1.2299e+04, 2.0880e+04,\n",
              "        8.1130e+03, 1.1166e+04, 3.5090e+03, 2.5140e+03, 2.8420e+03,\n",
              "        6.9800e+02, 8.2500e+02, 1.8600e+02, 1.2600e+02, 1.3800e+02,\n",
              "        3.7000e+01, 5.2000e+01, 1.9000e+01, 1.2000e+01, 2.0000e+01,\n",
              "        1.0000e+01, 6.0000e+00, 1.5000e+01, 2.0000e+00, 5.0000e+00,\n",
              "        2.0000e+00, 1.0000e+00, 2.0000e+00, 2.0000e+00, 3.0000e+00,\n",
              "        1.0000e+00, 2.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
              "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
              " array([  2.  ,   3.39,   4.78,   6.17,   7.56,   8.95,  10.34,  11.73,\n",
              "         13.12,  14.51,  15.9 ,  17.29,  18.68,  20.07,  21.46,  22.85,\n",
              "         24.24,  25.63,  27.02,  28.41,  29.8 ,  31.19,  32.58,  33.97,\n",
              "         35.36,  36.75,  38.14,  39.53,  40.92,  42.31,  43.7 ,  45.09,\n",
              "         46.48,  47.87,  49.26,  50.65,  52.04,  53.43,  54.82,  56.21,\n",
              "         57.6 ,  58.99,  60.38,  61.77,  63.16,  64.55,  65.94,  67.33,\n",
              "         68.72,  70.11,  71.5 ,  72.89,  74.28,  75.67,  77.06,  78.45,\n",
              "         79.84,  81.23,  82.62,  84.01,  85.4 ,  86.79,  88.18,  89.57,\n",
              "         90.96,  92.35,  93.74,  95.13,  96.52,  97.91,  99.3 , 100.69,\n",
              "        102.08, 103.47, 104.86, 106.25, 107.64, 109.03, 110.42, 111.81,\n",
              "        113.2 , 114.59, 115.98, 117.37, 118.76, 120.15, 121.54, 122.93,\n",
              "        124.32, 125.71, 127.1 , 128.49, 129.88, 131.27, 132.66, 134.05,\n",
              "        135.44, 136.83, 138.22, 139.61, 141.  ]),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X9QlPeBx/HPwrIl6HKw3K5Xe8ZL\nNI2ZqBiHRIWQFCOR2IlNY1BgMOPVTONFE3OhGmSs0vES8AcZY+KNqRrjYY0k9KalOQ+ZXDBjxg09\nszNUO+NYm/5hMYXdBAqCFsTn/si4FwIGXIH1u/t+zWQm+93v8/D9sA6ffZ7dfdZmWZYlAABgjJhw\nLwAAAFwfyhsAAMNQ3gAAGIbyBgDAMJQ3AACGobwBADCMPdwLGCq/vyPkbZOTE9Ta2jWMq7k5RUtO\nKXqykjPyREvWaMkpjWxWt9s54HhUHHnb7bHhXsKoiJacUvRkJWfkiZas0ZJTCk/WqChvAAAiCeUN\nAIBhKG8AAAxDeQMAYBjKGwAAw1DeAAAYhvIGAMAwlDcAAIahvAEAMAzlDQCAYShvAAAMQ3kDAGAY\nY75VDABGyo/KP+hz+83iuWFaCTA0lDeAiEMZI9Jx2hwAAMNQ3gAAGIbyBgDAMJQ3AACGobwBADAM\n5Q0AgGGG9FGxLVu26JNPPtHly5f19NNPa9q0aVq7dq16e3vldru1detWORwO1dTUaP/+/YqJidHi\nxYuVm5urnp4eFRcX6/z584qNjVVZWZkmTJig06dPq7S0VJJ055136mc/+9lI5gQAIGIMeuT98ccf\n6w9/+IOqqqq0Z88evfzyy9qxY4cKCgp08OBBTZw4UdXV1erq6tLOnTv11ltvqbKyUvv371dbW5ve\ne+89JSYm6u2339aKFStUUVEhSXrppZdUUlKiQ4cO6cKFC/rwww9HPCwAAJFg0PK+99579eqrr0qS\nEhMTdfHiRTU0NOihhx6SJGVlZcnr9aqxsVHTpk2T0+lUfHy8Zs6cKZ/PJ6/Xq+zsbElSenq6fD6f\nuru71dTUpOnTp/fZBwAAGNyg5R0bG6uEhARJUnV1tR544AFdvHhRDodDkpSSkiK/369AICCXyxXc\nzuVy9RuPiYmRzWZTIBBQYmJicO7VfQAAgMEN+fKo77//vqqrq/Xmm2/q4YcfDo5bljXg/OsZv9bc\nr0pOTpDdHjvE1fbndjtD3tYk0ZJTip6s5Bz9fY/075zHNPKMdtYhlfexY8e0a9cu7dmzR06nUwkJ\nCbp06ZLi4+PV3Nwsj8cjj8ejQCAQ3KalpUUzZsyQx+OR3+/XlClT1NPTI8uy5Ha71dbWFpx7dR/f\npLW1K8SIX/5S/f6OkLc3RbTklKInKzmHx/XueyTXwmMaeUYy67WeFAx62ryjo0NbtmzRG2+8oaSk\nJElfvnZ95MgRSVJdXZ0yMzOVmpqqkydPqr29XZ2dnfL5fEpLS1NGRoZqa2slSfX19Zo1a5bi4uJ0\n++2368SJE332AQAABjfokffhw4fV2tqq559/PjhWXl6u9evXq6qqSuPHj9djjz2muLg4FRUVafny\n5bLZbFq5cqWcTqcWLFig48ePKz8/Xw6HQ+Xl5ZKkkpISbdiwQVeuXFFqaqrS09NHLiUAABFk0PJe\nsmSJlixZ0m983759/cZycnKUk5PTZ+zqZ7u/bvLkyTp48OD1rBUAAIgrrAEAYBzKGwAAw1DeAAAY\nhvIGAMAwlDcAAIahvAEAMAzlDQCAYShvAAAMQ3kDAGAYyhsAAMNQ3gAAGIbyBgDAMJQ3AACGobwB\nADAM5Q0AgGEobwAADEN5AwBgGMobAADDUN4AABiG8gYAwDCUNwAAhqG8AQAwDOUNAIBhKG8AAAxD\neQMAYBjKGwAAw9iHMunMmTN65plntGzZMhUWFuq5555Ta2urJKmtrU0zZszQ008/rUcffVRTp06V\nJCUnJ2vHjh3q6OhQUVGROjo6lJCQoIqKCiUlJen48eN65ZVXFBsbqwceeEArV64cuZQAAESQQcu7\nq6tLmzZt0pw5c4JjO3bsCP7/unXrlJubK0m67bbbVFlZ2Wf7/fv367777tNTTz2lqqoq7d69W2vW\nrNG//du/ae/evRo3bpwKCws1f/58TZ48ebhyAQAQsQY9be5wOLR79255PJ5+93366afq6OjQ9OnT\nr7m91+tVdna2JCkrK0ter1fnzp3T3/3d3+nb3/62YmJi9OCDD8rr9d5ADAAAosegR952u112+8DT\n/uM//kOFhYXB24FAQM8995xaWlpUUFCghQsXKhAIyOVySZJSUlLU0tIiv98fHJMkl8ulc+fOfeM6\nkpMTZLfHDinUQNxuZ8jbmiRackrRk5Wco7/vkf6d85hGntHOOqTXvAfS3d2tTz75RKWlpZKkpKQk\nrV69WgsXLlRHR4dyc3M1e/bsPttYlhXyQltbu0Le1u12yu/vCHl7U0RLTil6spJzeFzvvkdyLTym\nkWcks17rSUHI7zb/3//93z6ny8eOHatFixYpLi5OLpdLU6dO1aeffiqPxyO/3y9Jam5ulsfjkcfj\nUSAQCG57dRwAAAwu5PI+efKkpkyZErz98ccfq6ysTNKXb3I7ffq0brvtNmVkZKi2tlaSVFdXp8zM\nTP3jP/6jLly4oD//+c+6fPmy6uvrlZGRcYNRAACIDoOeNj916pQ2b96spqYm2e12HTlyRK+99pr8\nfr9uvfXW4Ly0tDT96le/0pIlS9Tb26sf//jHGjdunJYuXao1a9aooKBAiYmJ2rp1qySptLRURUVF\nkqQFCxbotttuG6GIAABElkHLe+rUqf0+/iVJP/3pT/vuyG5XeXl5v3ljxozRv//7v/cbv/fee1VV\nVXU9awUAAOIKawAAGIfyBgDAMJQ3AACGobwBADAM5Q0AgGEobwAADEN5AwBgGMobAADDUN4AABiG\n8gYAwDCUNwAAhqG8AQAwDOUNAIBhKG8AAAxDeQMAYBjKGwAAw1DeAAAYhvIGAMAwlDcAAIahvAEA\nMAzlDQCAYShvAAAMQ3kDAGAYyhsAAMNQ3gAAGGZI5X3mzBnNmzdPBw4ckCQVFxfr0Ucf1dKlS7V0\n6VIdPXpUklRTU6NFixYpNzdX7777riSpp6dHRUVFys/PV2Fhoc6dOydJOn36tPLy8pSXl6eNGzeO\nQDQAACKTfbAJXV1d2rRpk+bMmdNn/IUXXlBWVlafeTt37lR1dbXi4uL0xBNPKDs7W/X19UpMTFRF\nRYU++ugjVVRUaPv27XrppZdUUlKi6dOnq6ioSB9++KEefPDB4U8IAECEGfTI2+FwaPfu3fJ4PN84\nr7GxUdOmTZPT6VR8fLxmzpwpn88nr9er7OxsSVJ6erp8Pp+6u7vV1NSk6dOnS5KysrLk9XqHIQ4A\nAJFv0CNvu90uu73/tAMHDmjfvn1KSUnRT3/6UwUCAblcruD9LpdLfr+/z3hMTIxsNpsCgYASExOD\nc1NSUuT3+79xHcnJCbLbY4cc7OvcbmfI25okWnJK0ZOVnKO/75H+nfOYRp7RzjpoeQ/kBz/4gZKS\nknTXXXfp5z//uV5//XXdc889feZYljXgtgONX2vuV7W2doWyVElf/lL9/o6QtzdFtOSUoicrOYfH\n9e57JNfCYxp5RjLrtZ4UhPRu8zlz5uiuu+6SJM2dO1dnzpyRx+NRIBAIzmlpaZHH45HH4wkeVff0\n9MiyLLndbrW1tQXnNjc3D3paHgAAfCmk8n722WeD7xpvaGjQHXfcodTUVJ08eVLt7e3q7OyUz+dT\nWlqaMjIyVFtbK0mqr6/XrFmzFBcXp9tvv10nTpyQJNXV1SkzM3OYIgEAENkGPW1+6tQpbd68WU1N\nTbLb7Tpy5IgKCwv1/PPP65ZbblFCQoLKysoUHx+voqIiLV++XDabTStXrpTT6dSCBQt0/Phx5efn\ny+FwqLy8XJJUUlKiDRs26MqVK0pNTVV6evqIhwUAIBIMWt5Tp05VZWVlv/H58+f3G8vJyVFOTk6f\nsdjYWJWVlfWbO3nyZB08ePB61goAAMQV1gAAMA7lDQCAYShvAAAMQ3kDAGAYyhsAAMNQ3gAAGIby\nBgDAMJQ3AACGobwBADAM5Q0AgGEobwAADEN5AwBgGMobAADDUN4AABiG8gYAwDCUNwAAhqG8AQAw\nDOUNAIBhKG8AAAxDeQMAYBjKGwAAw1DeAAAYhvIGAMAwlDcAAIahvAEAMIx9KJPOnDmjZ555RsuW\nLVNhYaE+++wzrVu3TpcvX5bdbtfWrVvldrt19913a+bMmcHt3nrrLV25ckXFxcU6f/68YmNjVVZW\npgkTJuj06dMqLS2VJN1555362c9+NiIBAQCINIMeeXd1dWnTpk2aM2dOcGz79u1avHixDhw4oOzs\nbO3bt0+SNHbsWFVWVgb/i42N1XvvvafExES9/fbbWrFihSoqKiRJL730kkpKSnTo0CFduHBBH374\n4QhFBAAgsgxa3g6HQ7t375bH4wmObdy4UfPnz5ckJScnq62t7Zrbe71eZWdnS5LS09Pl8/nU3d2t\npqYmTZ8+XZKUlZUlr9d7Q0EAAIgWg542t9vtstv7TktISJAk9fb26uDBg1q5cqUkqbu7W0VFRWpq\natL8+fP1z//8zwoEAnK5XJKkmJgY2Ww2BQIBJSYmBveXkpIiv9//jetITk6Q3R57fem+wu12hryt\nSaIlpxQ9Wck5+vse6d85j2nkGe2sQ3rNeyC9vb1au3atZs+eHTylvnbtWi1cuFA2m02FhYVKS0vr\nt51lWUMa+7rW1q5Qlyq32ym/vyPk7U0RLTml6MlKzuFxvfseybXwmEaekcx6rScFIb/bfN26dZo4\ncaJWrVoVHMvPz9eYMWOUkJCg2bNn68yZM/J4PMGj6p6eHlmWJbfb3edUe3Nzc5/T8gAA4NpCOvKu\nqalRXFycnnvuueDYp59+qp07d2rbtm3q7e2Vz+dTTk6OHA6HamtrlZmZqfr6es2aNUtxcXG6/fbb\ndeLECaWlpamurk5Lly4dtlAA8FU/Kv8g3EsAhtWg5X3q1Clt3rxZTU1NstvtOnLkiD7//HN961vf\nChbupEmTVFpaqn/4h3/QE088oZiYGM2dO1fTp0/X3XffrePHjys/P18Oh0Pl5eWSpJKSEm3YsEFX\nrlxRamqq0tPTRzYpAAARYtDynjp1qiorK4e0szVr1vQbu/rZ7q+bPHmyDh48OKT9AgCA/8cV1gAA\nMAzlDQCAYShvAAAMQ3kDAGAYyhsAAMNQ3gAAGIbyBgDAMJQ3AACGobwBADAM5Q0AgGEobwAADEN5\nAwBgGMobAADDhPR93gAQTQb6PvA3i+eGYSXAlzjyBgDAMJQ3AACGobwBADAM5Q0AgGEobwAADEN5\nAwBgGMobAADDUN4AABiG8gYAwDCUNwAAhqG8AQAwzJDK+8yZM5o3b54OHDggSfrss8+0dOlSFRQU\naPXq1eru7pYk1dTUaNGiRcrNzdW7774rSerp6VFRUZHy8/NVWFioc+fOSZJOnz6tvLw85eXlaePG\njSORDQCAiDRoeXd1dWnTpk2aM2dOcGzHjh0qKCjQwYMHNXHiRFVXV6urq0s7d+7UW2+9pcrKSu3f\nv19tbW167733lJiYqLffflsrVqxQRUWFJOmll15SSUmJDh06pAsXLujDDz8cuZQAAESQQcvb4XBo\n9+7d8ng8wbGGhgY99NBDkqSsrCx5vV41NjZq2rRpcjqdio+P18yZM+Xz+eT1epWdnS1JSk9Pl8/n\nU3d3t5qamjR9+vQ++wAAAIMb9CtB7Xa77Pa+0y5evCiHwyFJSklJkd/vVyAQkMvlCs5xuVz9xmNi\nYmSz2RQIBJSYmBice3Uf3yQ5OUF2e+zQk32N2+0MeVuTREtOKXqyknP0DWUtN7LemynrSIqWnNLo\nZ73h7/O2LOuGx68196taW7uub2Ff4XY75fd3hLy9KaIlpxQ9WckZHkNZS6jrvdmyjpRoySmNbNZr\nPSkI6d3mCQkJunTpkiSpublZHo9HHo9HgUAgOKelpSU4fvWouqenR5Zlye12q62tLTj36j4AAMDg\nQirv9PR0HTlyRJJUV1enzMxMpaam6uTJk2pvb1dnZ6d8Pp/S0tKUkZGh2tpaSVJ9fb1mzZqluLg4\n3X777Tpx4kSffQAAgMENetr81KlT2rx5s5qammS323XkyBFt27ZNxcXFqqqq0vjx4/XYY48pLi5O\nRUVFWr58uWw2m1auXCmn06kFCxbo+PHjys/Pl8PhUHl5uSSppKREGzZs0JUrV5Samqr09PQRDwsA\nQCQYtLynTp2qysrKfuP79u3rN5aTk6OcnJw+Y7GxsSorK+s3d/LkyTp48OD1rBUAAIgrrAEAYBzK\nGwAAw1DeAAAYhvIGAMAwlDcAAIahvAEAMAzlDQCAYShvAAAMQ3kDAGAYyhsAAMNQ3gAAGIbyBgDA\nMJQ3AACGobwBADAM5Q0AgGEobwAADEN5AwBgGMobAADDUN4AABiG8gYAwDD2cC8AAG42Pyr/INxL\nAL4RR94AABiG8gYAwDCUNwAAhqG8AQAwTEhvWHv33XdVU1MTvH3q1ClNnTpVXV1dSkhIkCS9+OKL\nmjp1qvbs2aPa2lrZbDatWrVKDz74oDo6OlRUVKSOjg4lJCSooqJCSUlJw5MIAIAIF1J55+bmKjc3\nV5L029/+Vv/93/+ts2fPqqysTN/97neD886dO6fDhw/r0KFDunDhggoKCnT//fdr//79uu+++/TU\nU0+pqqpKu3fv1po1a4YnEQAAEe6GT5vv3LlTzzzzzID3NTQ0KDMzUw6HQy6XS9/5znd09uxZeb1e\nZWdnS5KysrLk9XpvdBkAAESNG/qc9+9+9zt9+9vfltvtliTt2LFDra2tmjRpkkpKShQIBORyuYLz\nXS6X/H5/n/GUlBS1tLTcyDIAAIgqN1Te1dXV+uEPfyhJevLJJ3XnnXfq1ltv1caNG/WLX/yi33zL\nsoY0NpDk5ATZ7bEhr9Xtdoa8rUmiJacUPVnJeXO6kfWaljVU0ZJTGv2sN1TeDQ0NWr9+vSQFT4NL\n0ty5c3X48GHNmjVLf/rTn4Ljzc3N8ng88ng88vv9cjqdwbHBtLZ2hbxOt9spv78j5O1NES05pejJ\nSs6bV6jrNTFrKKIlpzSyWa/1pCDk17ybm5s1ZswYORwOWZalZcuWqb29XdKXpX7HHXdo9uzZOnr0\nqLq7u9Xc3KyWlhZNnjxZGRkZqq2tlSTV1dUpMzMz1GUAABB1Qj7y9vv9wdetbTabFi9erGXLlumW\nW27RuHHj9Oyzz+qWW27R4sWLVVhYKJvNptLSUsXExGjp0qVas2aNCgoKlJiYqK1btw5bIAAAIp3N\nGuqLzmF2I6ckouX0TbTklKInKzlDMxpfLPJm8dyQtuMxjTxGnTYHAADhQXkDAGAYyhsAAMNQ3gAA\nGIbyBgDAMDd0kRYAuBmMxrvLgZsJR94AABiG8gYAwDCUNwAAhqG8AQAwDOUNAIBhKG8AAAxDeQMA\nYBjKGwAAw1DeAAAYhvIGAMAwlDcAAIahvAEAMAzlDQCAYShvAAAMQ3kDAGAYyhsAAMNQ3gAAGIby\nBgDAMJQ3AACGsYeyUUNDg1avXq077rhDkvTd735XTz31lNauXave3l653W5t3bpVDodDNTU12r9/\nv2JiYrR48WLl5uaqp6dHxcXFOn/+vGJjY1VWVqYJEyYMazAAACJVSOUtSffdd5927NgRvL1u3ToV\nFBTokUce0SuvvKLq6mo99thj2rlzp6qrqxUXF6cnnnhC2dnZqq+vV2JioioqKvTRRx+poqJC27dv\nH5ZAAABEumE7bd7Q0KCHHnpIkpSVlSWv16vGxkZNmzZNTqdT8fHxmjlzpnw+n7xer7KzsyVJ6enp\n8vl8w7UMAAAiXshH3mfPntWKFSv017/+VatWrdLFixflcDgkSSkpKfL7/QoEAnK5XMFtXC5Xv/GY\nmBjZbDZ1d3cHtwcAANcWUnn/0z/9k1atWqVHHnlE586d05NPPqne3t7g/ZZlDbjd9Y5/VXJyguz2\n2FCWK0lyu50hb2uSaMkpRU9Wct6cbmS9pmUNVbTklEY/a0jlPW7cOC1YsECSdOutt+rv//7vdfLk\nSV26dEnx8fFqbm6Wx+ORx+NRIBAIbtfS0qIZM2bI4/HI7/drypQp6unpkWVZgx51t7Z2hbJUSV/+\nUv3+jpC3N0W05JSiJys5b16hrtfErKGIlpzSyGa91pOCkF7zrqmp0d69eyVJfr9fn3/+uR5//HEd\nOXJEklRXV6fMzEylpqbq5MmTam9vV2dnp3w+n9LS0pSRkaHa2lpJUn19vWbNmhXKMgAAiEohHXnP\nnTtXP/nJT/Q///M/6unpUWlpqe666y69+OKLqqqq0vjx4/XYY48pLi5ORUVFWr58uWw2m1auXCmn\n06kFCxbo+PHjys/Pl8PhUHl5+XDnAgAgYoVU3mPHjtWuXbv6je/bt6/fWE5OjnJycvqMXf1sNwAA\nuH5cYQ0AAMNQ3gAAGIbyBgDAMJQ3AACGobwBADAM5Q0AgGFCvrY5AITLj8o/CPcSgLDiyBsAAMNQ\n3gAAGIbyBgDAMJQ3AACGobwBADAM5Q0AgGEobwAADEN5AwBgGC7SAgAh+PqFYt4snhumlSAaceQN\nAIBhKG8AAAxDeQMAYBjKGwAAw/CGNQA3Pb5FDOiLI28AAAxDeQMAYBjKGwAAw/CaNwCMAC7igpEU\ncnlv2bJFn3zyiS5fvqynn35aH3zwgX7/+98rKSlJkrR8+XJ973vfU01Njfbv36+YmBgtXrxYubm5\n6unpUXFxsc6fP6/Y2FiVlZVpwoQJwxYKAIBIFlJ5f/zxx/rDH/6gqqoqtba26oc//KFmz56tF154\nQVlZWcF5XV1d2rlzp6qrqxUXF6cnnnhC2dnZqq+vV2JioioqKvTRRx+poqJC27dvH7ZQAABEspBe\n87733nv16quvSpISExN18eJF9fb29pvX2NioadOmyel0Kj4+XjNnzpTP55PX61V2drYkKT09XT6f\n7wYiAAAQXUIq79jYWCUkJEiSqqur9cADDyg2NlYHDhzQk08+qX/913/VF198oUAgIJfLFdzO5XLJ\n7/f3GY+JiZHNZlN3d/cwxAEAIPLd0BvW3n//fVVXV+vNN9/UqVOnlJSUpLvuuks///nP9frrr+ue\ne+7pM9+yrAH3c63xr0pOTpDdHhvyWt1uZ8jbmiRackrRk5WcZhjsQjJfzWd61qGKlpzS6GcNubyP\nHTumXbt2ac+ePXI6nZozZ07wvrlz56q0tFTz589XIBAIjre0tGjGjBnyeDzy+/2aMmWKenp6ZFmW\nHA7HN/681tauUJcqt9spv78j5O1NES05pejJSs7IcTVfNGSVoienNLJZr/WkIKTT5h0dHdqyZYve\neOON4LvLn332WZ07d06S1NDQoDvuuEOpqak6efKk2tvb1dnZKZ/Pp7S0NGVkZKi2tlaSVF9fr1mz\nZoWyDAAAolJIR96HDx9Wa2urnn/++eDY448/rueff1633HKLEhISVFZWpvj4eBUVFWn58uWy2Wxa\nuXKlnE6nFixYoOPHjys/P18Oh0Pl5eXDFggAgEhns4bygvNN4EZOSUTL6ZtoySlFT1ZyfikSvpjk\n6kVaeEwjjzGnzQEAQPhQ3gAAGIbyBgDAMJQ3AACGobwBADAM5Q0AgGEobwAADEN5AwBgGMobAADD\nUN4AABiG8gYAwDCUNwAAhgn5+7wjwde/7ODqFwcAAHAz48gbAADDUN4AABiG8gYAwDCUNwAAhqG8\nAQAwTFS/2xwAwoVPu+BGUN4AMAq+XtbAjeC0OQAAhqG8AQAwDOUNAIBheM17GA32BpThfoPK1/f3\nm4ofXNf8gdZwvWsc7vnh3l+o2wyncP/8cHi06NfhXgJgFMr7JhaNf8RNMNJPcEb754/EExz+7QIj\nK6zl/fLLL6uxsVE2m00lJSWaPn16OJcDAIARbJZlWeH4wb/97W+1d+9evfHGG/rjH/+okpISVVVV\nXXO+398R8s9yu50Dbj/SR0QAECrTz1Zc6+9uJBrJrG63c8DxsB15e71ezZs3T5I0adIk/fWvf9WF\nCxc0duzYcC2J8gVw0xjs75Hp5Y4bE7byDgQCuvvuu4O3XS6X/H5/WMsbAExBuUe3m+YNa4Odvb/W\nqYOhGmj7wd6dDQAI3Y3+3TbJaGcN2+e8PR6PAoFA8HZLS4vcbne4lgMAgDHCVt4ZGRk6cuSIJOn3\nv/+9PB4Pp8wBABiCsJ02nzlzpu6++27l5eXJZrNp48aN4VoKAABGCdtHxQAAQGi4tjkAAIahvAEA\nMExEl/fLL7+sJUuWKC8vT7/73e/CvZxht2XLFi1ZskSLFi1SXV2dPvvsMy1dulQFBQVavXq1uru7\nw73EYXPp0iXNmzdP//mf/xnROWtqarRw4UI9/vjjOnr0aERm7ezs1KpVq7R06VLl5eXp2LFjOn36\ntPLy8pSXlxcR7385c+aM5s2bpwMHDkjSNR/HmpoaLVq0SLm5uXr33XfDueSQDJRz2bJlKiws1LJl\ny+T3+yWZn1Pqn/WqY8eO6c477wzeHrWsVoRqaGiwfvzjH1uWZVlnz561Fi9eHOYVDS+v12s99dRT\nlmVZ1hdffGE9+OCDVnFxsXX48GHLsiyroqLC+sUvfhHOJQ6rV155xXr88cetX/7ylxGb84svvrAe\nfvhhq6Ojw2pubrbWr18fkVkrKyutbdu2WZZlWX/5y1+s+fPnW4WFhVZjY6NlWZb1wgsvWEePHg3n\nEm9IZ2enVVhYaK1fv96qrKy0LMsa8HHs7Oy0Hn74Yau9vd26ePGi9f3vf99qbW0N59Kvy0A5165d\na/3Xf/2XZVmWdeDAAWvz5s3G57SsgbNalmVdunTJKiwstDIyMoLzRitrxB55X+vyq5Hi3nvv1auv\nvipJSkxM1MWLF9XQ0KCHHnpIkpSVlSWv1xvOJQ6bP/7xjzp79qy+973vSVLE5vR6vZozZ47Gjh0r\nj8ejTZs2RWTW5ORktbW1SZLa29uVlJSkpqam4BcTmZ7T4XBo9+7d8ng8wbGBHsfGxkZNmzZNTqdT\n8fHxmjlzpnw+X7iWfd0GyrnN6ePdAAADz0lEQVRx40bNnz9f0v8/zqbnlAbOKkm7du1SQUGBHA6H\nJI1q1ogt70AgoOTk5ODtq5dfjRSxsbFKSEiQJFVXV+uBBx7QxYsXg/+IUlJSIibv5s2bVVxcHLwd\nqTn//Oc/69KlS1qxYoUKCgrk9XojMuv3v/99nT9/XtnZ2SosLNTatWuVmJgYvN/0nHa7XfHx8X3G\nBnocA4GAXC5XcI5pf6MGypmQkKDY2Fj19vbq4MGDevTRR43PKQ2c9U9/+pNOnz6tRx55JDg2mllv\nmsujjjQrQj8R9/7776u6ulpvvvmmHn744eB4pOT91a9+pRkzZmjChAkD3h8pOa9qa2vT66+/rvPn\nz+vJJ5/sky9Ssv7617/W+PHjtXfvXp0+fVorV66U0/n/l5aMlJzXcq18kZK7t7dXa9eu1ezZszVn\nzhz95je/6XN/pOQsKyvT+vXrv3HOSGaN2PKOhsuvHjt2TLt27dKePXvkdDqVkJCgS5cuKT4+Xs3N\nzf1O8Zjo6NGjOnfunI4ePaq//OUvcjgcEZlT+vKI7J577pHdbtett96qMWPGKDY2NuKy+nw+3X//\n/ZKkKVOm6G9/+5suX74cvD9Scn7VQP9mB/obNWPGjDCucnisW7dOEydO1KpVqyQN/LfY9JzNzc36\n9NNP9ZOf/ETSl5kKCwv17LPPjlrWiD1tHumXX+3o6NCWLVv0xhtvKCkpSZKUnp4ezFxXV6fMzMxw\nLnFYbN++Xb/85S/1zjvvKDc3V88880xE5pSk+++/Xx9//LGuXLmi1tZWdXV1RWTWiRMnqrGxUZLU\n1NSkMWPGaNKkSTpx4oSkyMn5VQM9jqmpqTp58qTa29vV2dkpn8+ntLS0MK/0xtTU1CguLk7PPfdc\ncCwSc44bN07vv/++3nnnHb3zzjvyeDw6cODAqGaN6Cusbdu2TSdOnAhefnXKlCnhXtKwqaqq0muv\nvabbbrstOFZeXq7169frb3/7m8aPH6+ysjLFxcWFcZXD67XXXtN3vvMd3X///XrxxRcjMuehQ4dU\nXV0tSfqXf/kXTZs2LeKydnZ2qqSkRJ9//rkuX76s1atXy+12a8OGDbpy5YpSU1O1bt26cC8zZKdO\nndLmzZvV1NQku92ucePGadu2bSouLu73ONbW1mrv3r2y2WwqLCzUwoULw738IRso5+eff65vfetb\nwQOlSZMmqbS01Oic0sBZX3vtteCB09y5c/XBB19+RetoZY3o8gYAIBJF7GlzAAAiFeUNAIBhKG8A\nAAxDeQMAYBjKGwAAw1DeAAAYhvIGAMAwlDcAAIb5P3/vEOxV2JatAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntr6ZDZdqbr7",
        "colab_type": "text"
      },
      "source": [
        "Our model is going to be made by multiple LSTM layers stacked on top of each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipTMZEH8pm5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class CharLstmLanguageModel(nn.Module):\n",
        "    def __init__(self, char_embedding_dim, lstm_dim, projection_size, n_lstm_layers=1, dropout=0):\n",
        "        super().__init__()\n",
        "        self.n_lstm_layers = n_lstm_layers\n",
        "        self.n_chars = 259\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.projection_size = projection_size\n",
        "        \n",
        "        # initialize lookup table of fixed dictionary and size, 0 = padding idx\n",
        "        self.char_embedder = nn.Embedding(self.n_chars, \n",
        "                                          self.char_embedding_dim, \n",
        "                                          padding_idx=258\n",
        "        )\n",
        "        \n",
        "        # lstm_dim = size of one lstm hidden layer\n",
        "        # n_lstm_layers = number of stacked lstms\n",
        "        \n",
        "        self.lstm = nn.LSTM(char_embedding_dim, \n",
        "                            lstm_dim, \n",
        "                            n_lstm_layers, \n",
        "                            batch_first=True, \n",
        "                            dropout=dropout, \n",
        "                            bidirectional=False,  # We want to use this for generation so we won't have all the seq together\n",
        "        )\n",
        "        \n",
        "        # creates a pipeline to transform the output of the lstm into a list where each position is a char idx\n",
        "        # and its values can be projected by ReLU to be the confidence for each character\n",
        "        self.projection = nn.Sequential(*[\n",
        "            nn.Linear(lstm_dim, self.projection_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(self.projection_size, self.n_chars),\n",
        "        ])\n",
        "        \n",
        "    def forward(self, char_ids, hidden=None, pack=True):\n",
        "        # char_ids of shape [b_sz, max_sq_len (w/ pads)]\n",
        "        x = self.char_embedder(char_ids)  # -> shape [b_sz, max_sq_len, char_emb_sz]\n",
        "        \n",
        "        x, hidden = self.lstm(x, hidden)  # -> shape [b_sz, max_sq_len, lstm_dim]\n",
        "\n",
        "        return self.projection(x), hidden  # -> projection's shape: [b_sz, max_sq_len, total_num_characters]\n",
        "                                           # -> (seq_len, batch, num_directions * hidden_size)\n",
        "                                           # hidden is a tuple (hidden_state, cell_state). Both are of shape (n_lstm_layers, b_sz, lstm_dim) \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KQTIt8VrIig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
        "\n",
        "def padded_collate(batch, padding_idx=258):\n",
        "    x = pad_sequence([elem['text'] for elem in batch], batch_first=True, padding_value=padding_idx)\n",
        "    y = pad_sequence([elem['next'] for elem in batch], batch_first=True, padding_value=padding_idx)\n",
        "    \n",
        "    return {'text': x, 'next': y}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F36DAdn3rMFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CharLstmLanguageModel(16,  # char_embedding_dim \n",
        "                              1024,  # lstm_hidden_dim\n",
        "                              512,\n",
        "                              n_lstm_layers=2,\n",
        "                              dropout=0.3,\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB0qNwk60R4Z",
        "colab_type": "text"
      },
      "source": [
        "In case you want to load an already trained model and fine tuning it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4pgI3sitd6b",
        "colab_type": "code",
        "outputId": "d09231fb-2b76-435a-f523-df037d97c628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharLstmLanguageModel(\n",
              "  (char_embedder): Embedding(259, 16, padding_idx=258)\n",
              "  (lstm): LSTM(16, 1024, num_layers=2, batch_first=True, dropout=0.3)\n",
              "  (projection): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3)\n",
              "    (3): Linear(in_features=512, out_features=259, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y60F9vc9rQZD",
        "colab_type": "code",
        "outputId": "9d37b641-c84e-47ca-8e30-f26d296911a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4oPejyQrV2a",
        "colab_type": "text"
      },
      "source": [
        "Let's define a train function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo_5LN8YrSxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataset, n_epochs, lr=0.01, batch_size=32, model_checkpoint_folder=None):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='elementwise_mean')\n",
        "    \n",
        "    train_sampler = BucketBatchSampler(dataset, batch_size, True, sort_key=lambda r: len(r['text']))\n",
        "    data_loader = DataLoader(dataset, batch_sampler=train_sampler, collate_fn=padded_collate, num_workers=mp.cpu_count())\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    plateau_scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n",
        "    \n",
        "    model = model.to(device).train()\n",
        "    \n",
        "    avg_loss = 0.0\n",
        "    avg_mom=0.98\n",
        "    losses = []\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        t = tqdm(iter(data_loader), leave=False, total=len(data_loader), miniters=0)\n",
        "        epoch_losses = []\n",
        "        for i, batch in enumerate(t):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            label = batch['next'].to(device)\n",
        "            pred, _ = model(batch['text'].to(device))\n",
        "            \n",
        "            batch_sz, seq_len, n_chars = pred.shape\n",
        "            \n",
        "            loss = criterion(pred.view(batch_sz * seq_len, -1), label.view(batch_sz * seq_len))\n",
        "            \n",
        "            loss_numeric = float(loss)\n",
        "            epoch_losses.append(loss_numeric)\n",
        "            avg_loss = avg_loss * avg_mom + loss_numeric * (1-avg_mom)\n",
        "            debias_loss = avg_loss / (1 - avg_mom**(i+1))\n",
        "            \n",
        "            lrs = \",\".join([str(param_group['lr']) for param_group in optimizer.param_groups])\n",
        "            t.set_postfix(loss=debias_loss, \n",
        "                          learning_rate=lrs,\n",
        "                          epoch=epoch,\n",
        "                         )\n",
        "\n",
        "            loss.backward()\n",
        "            # update weights using optimizer formula\n",
        "            optimizer.step()\n",
        "        \n",
        "        epoch_loss = sum(epoch_losses) / len(data_loader)\n",
        "        print(f\"\\nEpoch {epoch} loss: {epoch_loss}\")\n",
        "        losses.append(epoch_loss)\n",
        "        plateau_scheduler.step(epoch_loss)\n",
        "        epoch_losses = []\n",
        "        # save model\n",
        "        if model_checkpoint_folder:\n",
        "            model_save_path = model_checkpoint_folder + \"model_epoch_{}.pt\".format(epoch)\n",
        "            torch.save(model, model_save_path)\n",
        "    return losses\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArHzjGgvrZ_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CHECKPOINT_FOLDER = \"checkpoints/\"\n",
        "if not os.path.isdir(MODEL_CHECKPOINT_FOLDER):\n",
        "  os.makedirs(MODEL_CHECKPOINT_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcW4tHg-rcH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlwk9AGwreHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrMF4TfLpElg",
        "colab_type": "code",
        "outputId": "ee80b4ac-8c8f-4157-991a-a084855c567a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "losses = train(model, \n",
        "               wiki_dataset, \n",
        "               10, \n",
        "               lr=0.003, \n",
        "               batch_size=128, \n",
        "               model_checkpoint_folder=MODEL_CHECKPOINT_FOLDER\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/995 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:16: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                                                         \n",
            "Epoch 1 loss: 1.401535777051245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CharLstmLanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                                                         \n",
            "Epoch 2 loss: 1.3980323322454289\n",
            "                                                                                          \n",
            "Epoch 3 loss: 1.3928589433281866\n",
            "                                                                                          \n",
            "Epoch 4 loss: 1.387839260352916\n",
            "                                                                                          \n",
            "Epoch 5 loss: 1.3836720950040386\n",
            "                                                                                          \n",
            "Epoch 6 loss: 1.3807512765553729\n",
            "                                                                                          \n",
            "Epoch 7 loss: 1.3764163515076566\n",
            "                                                                                          \n",
            "Epoch 8 loss: 1.3733537849469402\n",
            "                                                                                          \n",
            "Epoch 9 loss: 1.370907208428311\n",
            "                                                                                           \n",
            "Epoch 10 loss: 1.3657020920485108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1JLkABuxtKn",
        "colab_type": "code",
        "outputId": "68b37177-1b0a-44fc-b2e3-9a8562c70939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from google.colab import files\n",
        "model_save_path = MODEL_CHECKPOINT_FOLDER + \"wiki_model_30epochs_checkpoint.pt\"\n",
        "torch.save(model, model_save_path)\n",
        "files.download(model_save_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CharLstmLanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEVz8BGTxz-S",
        "colab_type": "code",
        "outputId": "2516e16a-bf7c-4b53-a160-61e3a83bec1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.401535777051245, 1.3980323322454289, 1.3928589433281866, 1.387839260352916, 1.3836720950040386, 1.3807512765553729, 1.3764163515076566, 1.3733537849469402, 1.370907208428311, 1.3657020920485108]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_osAq0m0ep7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = [2.587973585919519, 1.8878660248751615, 1.7248724930250465, 1.647950033326844, 1.6195444668357695, 1.553175619439264, 1.5359190926479933, 1.5239209031938907, 1.5110083296670387, 1.4999794643128936, 1.4919527612139831, 1.4708082113433723, 1.4594857539962884, 1.4469362130117176, 1.4397834873678697, 1.4322743370005833, 1.423765480458437, 1.4182304330806637, 1.4115374595675636, 1.406341798041933, 1.401535777051245, 1.401535777051245, 1.3980323322454289, 1.3928589433281866, 1.387839260352916 , 1.3836720950040386 , 1.3807512765553729 , 1.3764163515076566 , 1.3733537849469402 , 1.370907208428311, 1.3657020920485108]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0MxiDGs0hgj",
        "colab_type": "code",
        "outputId": "17ae2e40-2d22-4d41-c7e0-a05f4ede8f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f71c42c48d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygmJS3t-5EL4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC7AqNwMx3jo",
        "colab_type": "text"
      },
      "source": [
        "# Sampling from the model\n",
        "\n",
        "\n",
        "The model may not have learned how to form valid utf-8 sequences (eg for emojis) so we offer an optional argument that sets all non-ASCII bytes to 0 probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8VmnEBQg9Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(model, start_token='', max_iters=100, temperature=1.0, no_unicode=False):\n",
        "  model = model.to('cpu')\n",
        "  enc = CharByteEncoder()\n",
        "  input_seq = enc.encode(start_token).tolist()[:-1] # Drop the end token\n",
        "  \n",
        "  hidden_prev = None\n",
        " \n",
        "  for t in range(max_iters):\n",
        "    x_t = torch.LongTensor([input_seq[t]]).unsqueeze(0)  # (b_sz=1, seq_len=1)\n",
        "    y_t, hidden_t = model(x_t, hidden_prev)\n",
        "    probs_t = F.softmax(y_t.squeeze() / temperature, dim=0)\n",
        "    \n",
        "    if no_unicode:\n",
        "      mask = torch.cat([torch.ones(128), torch.zeros(128), torch.ones(3)])\n",
        "      probs_t = probs_t * mask\n",
        "\n",
        "    x_next = torch.multinomial(probs_t, 1)  # Randomly picks, based on probabilities\n",
        "\n",
        "    input_seq.append(int(x_next))\n",
        "    if int(x_next) == enc.end_idx:\n",
        "      return enc.decode(torch.LongTensor(input_seq))\n",
        "    hidden_prev = hidden_t\n",
        "    \n",
        "  return enc.decode(torch.LongTensor(input_seq + [enc.end_idx]))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_6CA3DdhHFc",
        "colab_type": "code",
        "outputId": "60c20f66-465b-4d6c-88aa-114da5093d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample(model, no_unicode=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>smaller claim in the gun .</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMTkmQfq6l3c",
        "colab_type": "text"
      },
      "source": [
        "# Retraining on DadJokes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTBUlvRW7WZ0",
        "colab_type": "text"
      },
      "source": [
        "Let's see if pretraining on Wikipedia helped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isla9F2EM0Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DADJOKES_DATASET_PATH = \"shortjokes.csv\"\n",
        "DADJOKES_DATASET_FILE_ID = \"1bplfuUrJEnpi6r78LQtO3IufzCSSVJaC\"\n",
        "DADJOKES_DATASET_URL = \"https://github.com/amoudgl/short-jokes-dataset/raw/master/shortjokes.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX0HvW3m6kVF",
        "colab_type": "code",
        "outputId": "5f6d3e0e-819d-4662-aece-21d215c81d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import urllib.request\n",
        "...\n",
        "# Download the file from `url` and save it locally under `file_name`:\n",
        "urllib.request.urlretrieve(DADJOKES_DATASET_URL, DADJOKES_DATASET_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('shortjokes.csv', <http.client.HTTPMessage at 0x7f71e0296cf8>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHkVaNqw6kfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DadJokesDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.data = pd.read_csv(path, sep=',')['Joke'].tolist()\n",
        "        self.text_encoder = CharByteEncoder()\n",
        "        self.samples = []\n",
        "        for _ in range(len(self.data)):\n",
        "            joke = self.data.pop()\n",
        "            encoded_joke = self.text_encoder.encode(joke)\n",
        "            encoded_sample = self.generate_language_model_samples(encoded_joke)\n",
        "            self.samples.append(encoded_sample)\n",
        "        del self.data        \n",
        "        \n",
        "    def generate_language_model_samples(self, joke):\n",
        "        \"\"\"\n",
        "        Input: '<s>my funny joke</s>'\n",
        "        Output: {\n",
        "          text: '<s>my funny joke'\n",
        "          next: 'my funny joke</s>'\n",
        "        }\n",
        "        \"\"\"\n",
        "        res = {}\n",
        "        res['text'] = joke[:-1]\n",
        "        res['next'] = joke[1:]\n",
        "        return res\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.samples[i]\n",
        "    \n",
        "    def getitem_readable(self, i):\n",
        "        return {'text': self.text_encoder.decode(self.samples[i]['text']),\n",
        "               'next': self.text_encoder.decode(self.samples[i]['next'])}\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m50zCl-R6kij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jokes_dataset = DadJokesDataset(DADJOKES_DATASET_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fdX65Vk69uY",
        "colab_type": "text"
      },
      "source": [
        "Checking that the max size of a sequence is not too bad to make sure padding and memory are taken care of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdGTgIMw6kly",
        "colab_type": "code",
        "outputId": "49991392-4ee2-4ddf-918c-633241d3ad0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lengths = [len(p['text']) for p in jokes_dataset]\n",
        "print(max(lengths))\n",
        "plt.hist(lengths, bins=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  65.,   76.,  125.,  109.,  113.,  142.,  211.,  272.,  327.,\n",
              "         205.,  502.,  656.,  825., 1032., 1272., 1597., 2009., 2478.,\n",
              "        2880., 1597., 3411., 3790., 4162., 4623., 4715., 4784., 5104.,\n",
              "        5312., 5349., 2627., 5341., 5466., 5458., 5416., 5303., 5320.,\n",
              "        5157., 5186., 5027., 2452., 4730., 4599., 4662., 4359., 4202.,\n",
              "        4099., 3972., 3823., 3781., 1800., 3568., 3481., 3337., 3260.,\n",
              "        3163., 3011., 2966., 2911., 2899., 1452., 2742., 2696., 2784.,\n",
              "        2789., 2938., 3697., 4748., 6453., 5351.,  567.,  961.,  932.,\n",
              "         845.,  837.,  778.,  763.,  721.,  664.,  643.,  275.,  600.,\n",
              "         592.,  578.,  522.,  496.,  508.,  523.,  511.,  492.,  225.,\n",
              "         445.,  398.,  412.,  401.,  389.,  401.,  368.,  370.,  346.,\n",
              "         325.]),\n",
              " array([ 11. ,  12.9,  14.8,  16.7,  18.6,  20.5,  22.4,  24.3,  26.2,\n",
              "         28.1,  30. ,  31.9,  33.8,  35.7,  37.6,  39.5,  41.4,  43.3,\n",
              "         45.2,  47.1,  49. ,  50.9,  52.8,  54.7,  56.6,  58.5,  60.4,\n",
              "         62.3,  64.2,  66.1,  68. ,  69.9,  71.8,  73.7,  75.6,  77.5,\n",
              "         79.4,  81.3,  83.2,  85.1,  87. ,  88.9,  90.8,  92.7,  94.6,\n",
              "         96.5,  98.4, 100.3, 102.2, 104.1, 106. , 107.9, 109.8, 111.7,\n",
              "        113.6, 115.5, 117.4, 119.3, 121.2, 123.1, 125. , 126.9, 128.8,\n",
              "        130.7, 132.6, 134.5, 136.4, 138.3, 140.2, 142.1, 144. , 145.9,\n",
              "        147.8, 149.7, 151.6, 153.5, 155.4, 157.3, 159.2, 161.1, 163. ,\n",
              "        164.9, 166.8, 168.7, 170.6, 172.5, 174.4, 176.3, 178.2, 180.1,\n",
              "        182. , 183.9, 185.8, 187.7, 189.6, 191.5, 193.4, 195.3, 197.2,\n",
              "        199.1, 201. ]),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zql6mMnEGU5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIikVSTHGU2e",
        "colab_type": "code",
        "outputId": "54168d73-23ce-4177-af53-3cd638198795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar  4 17:45:08 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P8    24W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMoLs5BkvbxI",
        "colab_type": "code",
        "outputId": "e67250b9-1aaa-4444-ff9e-dce77e6c765d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc1e28a3-c516-4471-b141-037145899c3e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-dc1e28a3-c516-4471-b141-037145899c3e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dadjokes_from_wiki_model_10_epochs_checkpoint.pt to dadjokes_from_wiki_model_10_epochs_checkpoint (1).pt\n",
            "User uploaded file \"dadjokes_from_wiki_model_10_epochs_checkpoint.pt\" with length 53330801 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1LVlWiJvcpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftX3HKi-7CaD",
        "colab_type": "code",
        "outputId": "bb5eb8a4-46a7-4332-b17d-af40858aa771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "losses = train(model, \n",
        "               jokes_dataset, \n",
        "               10, \n",
        "               lr=0.01, \n",
        "               batch_size=128, \n",
        "               model_checkpoint_folder=MODEL_CHECKPOINT_FOLDER\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1809 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:16: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                                                        \n",
            "Epoch 1 loss: 2.0536029713795685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type CharLstmLanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                                                           \n",
            "Epoch 2 loss: 2.0050528563472563\n",
            "                                                                                           \n",
            "Epoch 3 loss: 1.9661188741096678\n",
            "                                                                                           \n",
            "Epoch 4 loss: 1.9397527801193144\n",
            "                                                                                           \n",
            "Epoch 5 loss: 1.934325941364168\n",
            "                                                                                           \n",
            "Epoch 6 loss: 1.9362773379283165\n",
            "                                                                                           \n",
            "Epoch 7 loss: 1.9262171407771282\n",
            "                                                                                           \n",
            "Epoch 8 loss: 1.9572868219326056\n",
            "                                                                                           \n",
            "Epoch 9 loss: 1.9326756192281669\n",
            "                                                                                           \n",
            "Epoch 10 loss: 1.9199754673845535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7QjGJSn7CfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "model_save_path = MODEL_CHECKPOINT_FOLDER + \"dadjokes_from_wiki_model_20_epochs_checkpoint.pt\"\n",
        "torch.save(model, model_save_path)\n",
        "files.download(model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbYzFxxL7Cik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = train(model, \n",
        "               jokes_dataset, \n",
        "               10, \n",
        "               lr=0.001, \n",
        "               batch_size=128, \n",
        "               model_checkpoint_folder=MODEL_CHECKPOINT_FOLDER\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3LF9btC7Tsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "model_save_path = MODEL_CHECKPOINT_FOLDER + \"dadjokes_from_wiki_model_30_epochs_checkpoint.pt\"\n",
        "torch.save(model, model_save_path)\n",
        "files.download(model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1CqxehiGn1F",
        "colab_type": "text"
      },
      "source": [
        "Now we should be able to sample jokes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnDWDcKuGsJX",
        "colab_type": "code",
        "outputId": "b59c2307-b64d-4404-bed9-cc0924b074dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample(model, no_unicode=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>Aow deeper. Thif to buttcaus the said and MS betwe wellsdis mo Jis.</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJaZlPs7GsQm",
        "colab_type": "code",
        "outputId": "88244b27-8c5d-40bc-cc8f-6d80f05536d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample(model, no_unicode=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>What eirilet a Hanging the bele beer peraligugant... Stemmind to mosriended Comete. I courn Jirdramm</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHGpaOJUAE42",
        "colab_type": "text"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "\n",
        "*   Use larger Wiki dataset (not fitting in RAM)\n",
        "*   Increase Dad Jokes dataset (scrape)\n",
        "*   Train Dad Jokes model more\n",
        "*   Use word encoder\n",
        "*   Use ASCII only\n",
        "*   Train on lowercase \n",
        "*   Remove jokes too short\n",
        "*   Add validation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kixi2Da0Gtf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}